{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "import sys\n",
    "import torch\n",
    "from tqdm.notebook import tnrange\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "from adaptis.inference.adaptis_sampling import get_panoptic_segmentation\n",
    "from adaptis.inference.prediction_model import AdaptISPrediction\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adaptis.data.toy import ToyDataset\n",
    "\n",
    "dataset_path = '/data/adaptis_toy/augmented'\n",
    "dataset = ToyDataset(dataset_path, split='test', with_segmentation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "> <ipython-input-3-fc618795dcfb>(4)<module>()->None\n",
      "-> import pdb; pdb.set_trace()\n",
      "(Pdb) n\n",
      "> /home/chuong/anaconda3/envs/adaptis/lib/python3.7/site-packages/IPython/core/interactiveshell.py(3334)run_code()\n",
      "-> sys.excepthook = old_excepthook\n",
      "(Pdb) n\n",
      "> /home/chuong/anaconda3/envs/adaptis/lib/python3.7/site-packages/IPython/core/interactiveshell.py(3350)run_code()\n",
      "-> outflag = False\n"
     ]
    }
   ],
   "source": [
    "from adaptis.model.toy.models import get_unet_model\n",
    "\n",
    "model = get_unet_model(norm_layer=torch.nn.BatchNorm2d, with_proposals=True)\n",
    "import pdb; pdb.set_trace()\n",
    "pmodel = AdaptISPrediction(model, dataset, device)\n",
    "\n",
    "weights_path = '../experiments/toy_unet/checkpoints/toy_proposals_last_checkpoint.params'\n",
    "pmodel.load_parameters(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(pmodel)\n",
    "print(pmodel.net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adaptis.coco.panoptic_metric import PQStat, pq_compute, print_pq_stat\n",
    "\n",
    "\n",
    "def test_model(pmodel, dataset,\n",
    "               sampling_algorithm, sampling_params,\n",
    "               use_flip=False, cut_radius=-1):\n",
    "    pq_stat = PQStat()\n",
    "    categories = dataset._generate_coco_categories()\n",
    "    categories = {x['id']: x for x in categories}\n",
    "\n",
    "    for indx in tnrange(len(dataset)):\n",
    "        sample = dataset.get_sample(indx)\n",
    "        pred = get_panoptic_segmentation(pmodel, sample['image'],\n",
    "                                         sampling_algorithm=sampling_algorithm,\n",
    "                                         use_flip=use_flip, cut_radius=cut_radius, **sampling_params)\n",
    "        \n",
    "        \n",
    "        coco_sample = dataset.convert_to_coco_format(sample)\n",
    "        pred = dataset.convert_to_coco_format(pred)\n",
    "\n",
    "        pq_stat = pq_compute(pq_stat, pred, coco_sample, categories)\n",
    "    \n",
    "    print_pq_stat(pq_stat, categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test proposals-based point sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposals_sampling_params = {\n",
    "    'thresh1': 0.4,\n",
    "    'thresh2': 0.5,\n",
    "    'ithresh': 0.3,\n",
    "    'fl_prob': 0.10,\n",
    "    'fl_eps': 0.003,\n",
    "    'fl_blur': 2,\n",
    "    'max_iters': 100\n",
    "}\n",
    "\n",
    "# test_model(pmodel, dataset,\n",
    "#            sampling_algorithm='proposals',\n",
    "#            sampling_params=proposals_sampling_params,\n",
    "#            use_flip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposals_sampling_params = {\n",
    "    'thresh1': 0.4,\n",
    "    'thresh2': 0.5,\n",
    "    'ithresh': 0.3,\n",
    "    'fl_prob': 0.10,\n",
    "    'fl_eps': 0.003,\n",
    "    'fl_blur': 2,\n",
    "    'max_iters': 100\n",
    "}\n",
    "\n",
    "test_model(pmodel, dataset,\n",
    "           sampling_algorithm='proposals',\n",
    "           sampling_params=proposals_sampling_params,\n",
    "           use_flip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test random sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sampling_params = {\n",
    "    'thresh1': 0.4,\n",
    "    'thresh2': 0.5,\n",
    "    'ithresh': 0.3,\n",
    "    'num_candidates': 7,\n",
    "    'num_iters': 40\n",
    "}\n",
    "\n",
    "test_model(pmodel, dataset,\n",
    "           sampling_algorithm='random', sampling_params=random_sampling_params,\n",
    "           use_flip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sampling_params = {\n",
    "    'thresh1': 0.4,\n",
    "    'thresh2': 0.5,\n",
    "    'ithresh': 0.3,\n",
    "    'num_candidates': 7,\n",
    "    'num_iters': 40\n",
    "}\n",
    "\n",
    "test_model(pmodel, dataset,\n",
    "           sampling_algorithm='random', sampling_params=random_sampling_params,\n",
    "           use_flip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adaptis.utils.vis import visualize_instances, visualize_proposals\n",
    "\n",
    "\n",
    "proposals_sampling_params = {\n",
    "    'thresh1': 0.5,\n",
    "    'thresh2': 0.5,\n",
    "    'ithresh': 0.3,\n",
    "    'fl_prob': 0.10,\n",
    "    'fl_eps': 0.003,\n",
    "    'fl_blur': 2,\n",
    "    'max_iters': 100\n",
    "}\n",
    "\n",
    "vis_samples = [15, 25, 42]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(nrows=len(vis_samples), ncols=3, figsize=(7,7))\n",
    "fig.tight_layout(pad=0.0, w_pad=0.0, h_pad=0.0)\n",
    "\n",
    "for row_indx, sample_indx in enumerate(vis_samples):\n",
    "    sample = dataset.get_sample(sample_indx)\n",
    "    pred = get_panoptic_segmentation(pmodel, sample['image'],\n",
    "                                 sampling_algorithm='proposals',\n",
    "                                 use_flip=True, **proposals_sampling_params)\n",
    "    \n",
    "    for i in range(3):\n",
    "        ax[row_indx, i].axis('off')\n",
    "\n",
    "    if row_indx == 0:\n",
    "        ax[row_indx, 0].set_title('Input Image', fontsize=14)\n",
    "        ax[row_indx, 1].set_title('Instance Segmentation', fontsize=14)\n",
    "        ax[row_indx, 2].set_title('Proposal Map', fontsize=14)\n",
    "    ax[row_indx, 0].imshow(sample['image'])\n",
    "    ax[row_indx, 1].imshow(visualize_instances(pred['instances_mask']))\n",
    "    ax[row_indx, 2].imshow(visualize_proposals(pred['proposals_info']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test challenging samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adaptis.utils.vis import visualize_instances, visualize_proposals\n",
    "\n",
    "dense_sampling_params = {\n",
    "    'thresh1': 0.75,\n",
    "    'thresh2': 0.50,\n",
    "    'ithresh': 0.3,\n",
    "    'fl_prob': 0.10,\n",
    "    'fl_eps': 0.003,\n",
    "    'fl_blur': 2,\n",
    "    'max_iters': 1000,\n",
    "    'cut_radius': 48\n",
    "}\n",
    "\n",
    "sample_image = cv2.imread('../images/toy_samples/250_sample_noisy.jpg')[:, :, ::-1].copy()\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(sample_image)\n",
    "\n",
    "pred = get_panoptic_segmentation(pmodel, sample_image,\n",
    "                                 sampling_algorithm='proposals',\n",
    "                                 use_flip=True, **dense_sampling_params)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(visualize_instances(pred['instances_mask'],\n",
    "                               boundaries_color=(150, 150, 150), boundaries_alpha=0.8))\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(visualize_proposals(pred['proposals_info']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('adaptis': conda)",
   "language": "python",
   "name": "python37664bitadaptisconda0cea7aae873749daa0c99619ac058e30"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
